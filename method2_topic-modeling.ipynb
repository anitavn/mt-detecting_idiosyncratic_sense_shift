{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drive mount"
      ],
      "metadata": {
        "id": "xGYmUGrIQD2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "folder_path = '/content/drive/My Drive/MSc Computer Science/Master Thesis/trial_data/'\n",
        "\n",
        "for f in os.listdir(folder_path):\n",
        "    print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs860BlhQMPo",
        "outputId": "2b396dfc-63d8-4a46-aa76-9a401c97a1f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "diachronic.xlsx\n",
            "speaker1.xlsx\n",
            "speaker2.xlsx\n",
            "speaker3.xlsx\n",
            "speaker4.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klZ-ddQmty03"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.26.4 pandas==2.2.2 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wJoBZFNI8GH_",
        "outputId": "5187e62e-a0c5-4d4b-e476-604761e1166a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.2.2\n",
            "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas==2.2.2)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==2.2.2)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas==2.2.2)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.2.2)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 pandas-2.2.2 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "six"
                ]
              },
              "id": "1f2de37c00544202ba7e46181460e7fb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tomotopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkkB-0zOy_Ol",
        "outputId": "dfc44326-6450-4550-ed78-c51a7aab4476"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tomotopy\n",
            "  Downloading tomotopy-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tomotopy) (1.26.4)\n",
            "Downloading tomotopy-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/11.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/11.6 MB\u001b[0m \u001b[31m126.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m10.3/11.6 MB\u001b[0m \u001b[31m151.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m163.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tomotopy\n",
            "Successfully installed tomotopy-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download nb_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY0zt4fICzdG",
        "outputId": "0e536f5a-32c1-45b2-942d-30dde56109db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nb-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/nb_core_news_md-3.8.0/nb_core_news_md-3.8.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nb-core-news-md\n",
            "Successfully installed nb-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('nb_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "a-TzQtlV8Vw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19865aa-659c-4399-afba-bb75dcc67e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9vRfLQluN2F"
      },
      "source": [
        "# Helpers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import jensenshannon\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "nlp = spacy.load(\"nb_core_news_md\")\n",
        "\n",
        "def compute_jsd_for_lemma(distr_r, distr_f, word_forms):\n",
        "    def average_distribution(forms, distr):\n",
        "        vectors = [distr[w] for w in forms if w in distr]\n",
        "        if not vectors:\n",
        "            return None\n",
        "\n",
        "        return np.mean(np.stack(vectors), axis=0)\n",
        "\n",
        "    lemmatized_forms = set()\n",
        "    for word in word_forms:\n",
        "        doc = nlp(word.lower())\n",
        "        for token in doc:\n",
        "            if token.is_alpha and not token.is_stop:\n",
        "                lemmatized_forms.add(token.lemma_)\n",
        "\n",
        "    p = average_distribution(lemmatized_forms, distr_r)\n",
        "    q = average_distribution(lemmatized_forms, distr_f)\n",
        "\n",
        "    return jensenshannon(p, q)"
      ],
      "metadata": {
        "id": "hjNj_Yjf46s0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_word_forms_by_stem(usages_a, usages_b, stem):\n",
        "    all_usages = usages_a + usages_b\n",
        "    word_forms = set()\n",
        "\n",
        "    for text in all_usages:\n",
        "        tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "        for token in tokens:\n",
        "            if token.startswith(stem):\n",
        "                word_forms.add(token)\n",
        "\n",
        "    return sorted(word_forms)"
      ],
      "metadata": {
        "id": "D3clfAzs5HP8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"nb_core_news_md\")\n",
        "\n",
        "def compute_noveltyy(ref_usages, foc_usages, all_topics, alpha=1.0):\n",
        "    def assign_sense_to_doc(doc_text, topics):\n",
        "      doc = nlp(doc_text.lower())\n",
        "      words = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
        "\n",
        "      topic_scores = []\n",
        "      for i, topic in enumerate(topics):\n",
        "          score = sum(topic.get(word, 0) for word in words)\n",
        "          topic_scores.append((i, score))\n",
        "\n",
        "      best_topic_i, best_score = max(topic_scores, key=lambda x: x[1])\n",
        "      return best_topic_i, best_score, topic_scores\n",
        "\n",
        "    ref_assignments = [assign_sense_to_doc(doc, all_topics)[0] for doc in ref_usages]\n",
        "    foc_assignments = [assign_sense_to_doc(doc, all_topics)[0] for doc in foc_usages]\n",
        "\n",
        "    T = set(range(len(all_topics)))\n",
        "    T_size = len(T)\n",
        "\n",
        "    count_ref = Counter(ref_assignments)\n",
        "    print('count ref', count_ref)\n",
        "    count_foc = Counter(foc_assignments)\n",
        "    print('count foc', count_foc)\n",
        "\n",
        "    # Total counts\n",
        "    total_ref = sum(count_ref.values())\n",
        "    total_foc = sum(count_foc.values())\n",
        "\n",
        "    novelty_scores = {}\n",
        "    for t in T: # Apply additive smoothing as per equation\n",
        "        p_f = (count_foc.get(t, 0) + alpha / T_size) / (total_foc + alpha)\n",
        "        p_r = (count_ref.get(t, 0) + alpha / T_size) / (total_ref + alpha)\n",
        "\n",
        "        novelty_scores[t] = (p_f - p_r) / p_r if p_r > 0 else float('inf')\n",
        "\n",
        "    max_novelty_sense = max(novelty_scores, key=novelty_scores.get)\n",
        "    max_novelty = novelty_scores[max_novelty_sense]\n",
        "\n",
        "    return max_novelty_sense, max_novelty, novelty_scores\n"
      ],
      "metadata": {
        "id": "y-Y__Db8hSf9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import tomotopy as tp\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "nlp = spacy.load(\"nb_core_news_md\")\n",
        "\n",
        "def lemmatize_and_filter(text):\n",
        "    doc = nlp(text.lower())\n",
        "    return [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
        "\n",
        "def train_model(usages_a, usages_b, iterations=1000, seed=42):\n",
        "    texts = [lemmatize_and_filter(doc) for doc in usages_a + usages_b]\n",
        "\n",
        "    model = tp.HDPModel(tw=tp.TermWeight.ONE, seed=seed)\n",
        "    for text in texts:\n",
        "        if text:\n",
        "            model.add_doc(text)\n",
        "\n",
        "    model.train(iter=iterations, workers=1)\n",
        "    return model"
      ],
      "metadata": {
        "id": "yl6mlySH1Pax"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_topic_distributions(model, doc_indices):\n",
        "    word_topic_counts = defaultdict(lambda: np.zeros(model.k))\n",
        "\n",
        "    for i in doc_indices:\n",
        "        doc = model.docs[i]\n",
        "        for word_id, topic_id in zip(doc.words, doc.topics):\n",
        "            word = model.vocabs[word_id]\n",
        "            word_topic_counts[word][topic_id] += 1\n",
        "\n",
        "    word_topic_dists = {}\n",
        "    for word, topic_counts in word_topic_counts.items():\n",
        "        total = topic_counts.sum()\n",
        "        if total > 0:\n",
        "            word_topic_dists[word] = topic_counts / total\n",
        "\n",
        "    return word_topic_dists\n",
        "\n",
        "\n",
        "def get_topic_word_lists(model, num_words=10):\n",
        "    topic_dicts = []\n",
        "    for k in range(model.k):\n",
        "        topic_words = model.get_topic_words(k, top_n=num_words)\n",
        "        topic_dict = {word: weight for word, weight in topic_words}\n",
        "        topic_dicts.append(topic_dict)\n",
        "    return topic_dicts"
      ],
      "metadata": {
        "id": "b-_Ik1y21YH5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_topic_distributions_corpus_pair(model, usages_a, usages_b):\n",
        "    index_a = list(range(len(usages_a)))\n",
        "    index_b = list(range(len(usages_a), len(usages_a) + len(usages_b)))\n",
        "\n",
        "    dist_a = get_word_topic_distributions(model, index_a)\n",
        "    dist_b = get_word_topic_distributions(model, index_b)\n",
        "\n",
        "    return dist_a, dist_b"
      ],
      "metadata": {
        "id": "beZNgYLP3WlC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment\n"
      ],
      "metadata": {
        "id": "3r3ZwXgbQwbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diachronic"
      ],
      "metadata": {
        "id": "x7dfUbHjQ6F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = 'diachronic.xlsx'\n",
        "folder_path = '/content/drive/My Drive/MSc Computer Science/Master Thesis/trial_data/'\n",
        "\n",
        "df_d = pd.read_excel(folder_path + filename)\n",
        "# df_d"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rzLq3MXsQyeg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tg1_usages = df_d[df_d['usage_id'].str.contains(\"tg1\", na=False)]['text'].tolist()\n",
        "tg2_usages = df_d[df_d['usage_id'].str.contains(\"tg2\", na=False)]['text'].tolist()"
      ],
      "metadata": {
        "id": "8N1nH6R2RHFt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(tg1_usages, tg2_usages)"
      ],
      "metadata": {
        "id": "pR2YrUIV1e5B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSD"
      ],
      "metadata": {
        "id": "o67kR9kS888-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tw = \"bærekraft\"\n",
        "words_forms_d = get_word_forms_by_stem(tg1_usages, tg2_usages, tw)\n",
        "words_forms_d"
      ],
      "metadata": {
        "id": "m1laJ8Fi2IkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d454d79a-d90e-409c-c5d3-e8affb33181f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bærekraft',\n",
              " 'bærekraftig',\n",
              " 'bærekraftige',\n",
              " 'bærekraftmål',\n",
              " 'bærekraftsmålene',\n",
              " 'bærekraftutfordringene']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distr_tg1, distr_tg2 = word_topic_distributions_corpus_pair(model, tg1_usages, tg2_usages)"
      ],
      "metadata": {
        "id": "eJJDP5DfRCdE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_jsd_for_lemma(distr_tg1, distr_tg2, words_forms_d) # np.float64(0.8191556014513339)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWUcd3h8sIa",
        "outputId": "ce0a7095-6c39-4404-bd80-193aa98567dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7821977034161408"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Novelty"
      ],
      "metadata": {
        "id": "935lu6W49Cth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dia_topics = get_topic_word_lists(model, num_words=10)"
      ],
      "metadata": {
        "id": "o3WQOQwc9EAw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dia_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vok25orgZXER",
        "outputId": "b356961a-eb2c-44f6-dfce-84402cf6174c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_novelty_sense, max_novelty_score, novelty_scores = compute_noveltyy(\n",
        "    tg1_usages, tg2_usages, dia_topics)\n",
        "\n",
        "print(\"Most novel sense index:\", max_novelty_sense)\n",
        "print(\"Novelty score of the most novel sense:\", max_novelty_score)\n",
        "print(\"All novelty scores per sense:\", novelty_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f3B5taUSapV",
        "outputId": "c510861d-d6ae-4116-be44-179b840b6158"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count ref Counter({53: 3, 45: 3, 29: 2, 12: 1, 36: 1, 47: 1, 50: 1, 33: 1, 18: 1, 31: 1, 14: 1, 26: 1, 35: 1, 42: 1, 49: 1, 54: 1, 38: 1, 51: 1, 22: 1, 32: 1, 34: 1, 11: 1, 37: 1, 27: 1, 40: 1})\n",
            "count foc Counter({28: 1, 49: 1, 7: 1, 25: 1, 44: 1, 1: 1, 41: 1, 4: 1, 45: 1, 3: 1, 5: 1, 24: 1, 19: 1, 30: 1, 9: 1, 8: 1, 2: 1, 6: 1, 52: 1, 16: 1, 15: 1, 46: 1, 0: 1, 17: 1, 20: 1, 21: 1, 10: 1, 13: 1, 39: 1, 23: 1})\n",
            "Most novel sense index: 0\n",
            "Novelty score of the most novel sense: 62.00000000000001\n",
            "All novelty scores per sense: {0: 62.00000000000001, 1: 62.00000000000001, 2: 62.00000000000001, 3: 62.00000000000001, 4: 62.00000000000001, 5: 62.00000000000001, 6: 62.00000000000001, 7: 62.00000000000001, 8: 62.00000000000001, 9: 62.00000000000001, 10: 62.00000000000001, 11: -0.9841269841269841, 12: -0.9841269841269841, 13: 62.00000000000001, 14: -0.9841269841269841, 15: 62.00000000000001, 16: 62.00000000000001, 17: 62.00000000000001, 18: -0.9841269841269841, 19: 62.00000000000001, 20: 62.00000000000001, 21: 62.00000000000001, 22: -0.9841269841269841, 23: 62.00000000000001, 24: 62.00000000000001, 25: 62.00000000000001, 26: -0.9841269841269841, 27: -0.9841269841269841, 28: 62.00000000000001, 29: -0.9920000000000001, 30: 62.00000000000001, 31: -0.9841269841269841, 32: -0.9841269841269841, 33: -0.9841269841269841, 34: -0.9841269841269841, 35: -0.9841269841269841, 36: -0.9841269841269841, 37: -0.9841269841269841, 38: -0.9841269841269841, 39: 62.00000000000001, 40: -0.9841269841269841, 41: 62.00000000000001, 42: -0.9841269841269841, 43: 0.0, 44: 62.00000000000001, 45: -0.6631016042780749, 46: 62.00000000000001, 47: -0.9841269841269841, 48: 0.0, 49: 0.0, 50: -0.9841269841269841, 51: -0.9841269841269841, 52: 62.00000000000001, 53: -0.9946524064171124, 54: -0.9841269841269841, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count ref Counter({39: 2, 27: 2, 55: 2, 23: 2, 12: 1, 38: 1, 30: 1, 46: 1, 37: 1, 0: 1, 24: 1, 26: 1, 15: 1, 1: 1, 32: 1, 29: 1, 6: 1, 44: 1, 14: 1, 22: 1, 10: 1, 2: 1, 20: 1, 51: 1, 47: 1, 4: 1})\n",
        "count foc Counter({55: 3, 43: 1, 41: 1, 34: 1, 19: 1, 13: 1, 42: 1, 11: 1, 36: 1, 25: 1, 21: 1, 49: 1, 33: 1, 35: 1, 18: 1, 17: 1, 9: 1, 5: 1, 28: 1, 48: 1, 40: 1, 31: 1, 8: 1, 16: 1, 45: 1, 3: 1, 50: 1, 7: 1})\n",
        "Most novel sense index: 3\n",
        "Novelty score of the most novel sense: 63.0\n",
        "All novelty scores per sense: {0: -0.984375, 1: -0.984375, 2: -0.984375, 3: 63.0, 4: -0.984375, 5: 63.0, 6: -0.984375, 7: 63.0, 8: 63.0, 9: 63.0, 10: -0.984375, 11: 63.0, 12: -0.984375, 13: 63.0, 14: -0.984375, 15: -0.984375, 16: 63.0, 17: 63.0, 18: 63.0, 19: 63.0, 20: -0.984375, 21: 63.0, 22: -0.984375, 23: -0.9921259842519685, 24: -0.984375, 25: 63.0, 26: -0.984375, 27: -0.9921259842519685, 28: 63.0, 29: -0.984375, 30: -0.984375, 31: 63.0, 32: -0.984375, 33: 63.0, 34: 63.0, 35: 63.0, 36: 63.0, 37: -0.984375, 38: -0.984375, 39: -0.9921259842519685, 40: 63.0, 41: 63.0, 42: 63.0, 43: 63.0, 44: -0.984375, 45: 63.0, 46: -0.984375, 47: -0.984375, 48: 63.0, 49: 63.0, 50: 63.0, 51: -0.984375, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.49606299212598426, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0}"
      ],
      "metadata": {
        "id": "vq0kK94VEpK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speaker 1"
      ],
      "metadata": {
        "id": "_1D_r5r8Txax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = 'speaker1.xlsx'\n",
        "folder_path = '/content/drive/My Drive/MSc Computer Science/Master Thesis/trial_data/'\n",
        "\n",
        "df_s1 = pd.read_excel(folder_path + filename)\n",
        "#df_s1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RqRQr0VNTv1L"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs1_usages = df_s1[df_s1['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s1_usages = df_s1[df_s1['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()"
      ],
      "metadata": {
        "id": "UhOSg7pYT532"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s1 = train_model(gs1_usages, s1_usages)"
      ],
      "metadata": {
        "id": "5Sm-GP2Q4Ver"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSD"
      ],
      "metadata": {
        "id": "KAVcnaFu-X9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tw = \"bærekraft\"\n",
        "word_forms_s1 = get_word_forms_by_stem(gs1_usages, s1_usages, tw)\n",
        "word_forms_s1\n",
        "\n",
        "# ['bærekraft','bærekraftbegrepene','bærekraften','bærekraftig','bærekraftige','bærekraftindikator','bærekraftindikatorer','bærekraftperspektiv','bærekraftsindikatorer','bærekraftskriteriene','bærekraftskvalitet','bærekraftsmålet']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmgn6Dd6-Zkm",
        "outputId": "8777aff0-a5e3-4d1f-ad77-a37fc87f7ae6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bærekraft',\n",
              " 'bærekraftbegrepene',\n",
              " 'bærekraften',\n",
              " 'bærekraftig',\n",
              " 'bærekraftige',\n",
              " 'bærekraftindikator',\n",
              " 'bærekraftindikatorer',\n",
              " 'bærekraftperspektiv',\n",
              " 'bærekraftsindikatorer',\n",
              " 'bærekraftskriteriene',\n",
              " 'bærekraftskvalitet',\n",
              " 'bærekraftsmålet']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distr_gs1, distr_s1 = word_topic_distributions_corpus_pair(model_s1, gs1_usages, s1_usages)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "POL71NV4-lzj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_jsd_for_lemma(distr_gs1, distr_s1, word_forms_s1) # 0.7631599710096147"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTsQzZhR-jNu",
        "outputId": "fd36ac2c-74d2-4e71-ea4a-a121c266acad"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7505834648136037"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Novelty"
      ],
      "metadata": {
        "id": "0hq8Dksi_chr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1_topics = get_topic_word_lists(model_s1)"
      ],
      "metadata": {
        "id": "jwNa4Vx1UHDp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(s1_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT6Q77Y_ZPhO",
        "outputId": "21404bf0-b3cf-4da3-af5e-35d7cee59c55"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_novelty_sense, max_novelty_score, novelty_scores = compute_noveltyy(\n",
        "    gs1_usages, s1_usages, s1_topics)\n",
        "\n",
        "print(\"Most novel sense index:\", max_novelty_sense)\n",
        "print(\"Novelty score of the most novel sense:\", max_novelty_score) # Novelty score of the most novel sense: 61.0\n",
        "print(\"All novelty scores per sense:\", novelty_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiN9bYDEUQyy",
        "outputId": "b940af6f-e446-4530-8526-200077d08eaa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count ref Counter({39: 3, 24: 2, 30: 1, 7: 1, 35: 1, 2: 1, 37: 1, 29: 1, 38: 1, 13: 1, 46: 1, 21: 1, 20: 1, 42: 1, 16: 1, 54: 1, 15: 1, 25: 1, 10: 1, 17: 1, 23: 1, 1: 1, 4: 1, 8: 1, 45: 1, 18: 1, 14: 1})\n",
            "count foc Counter({45: 3, 50: 2, 39: 2, 40: 1, 6: 1, 11: 1, 22: 1, 27: 1, 31: 1, 3: 1, 44: 1, 9: 1, 34: 1, 28: 1, 12: 1, 5: 1, 0: 1, 41: 1, 47: 1, 26: 1, 48: 1, 32: 1, 55: 1, 33: 1, 19: 1, 36: 1})\n",
            "Most novel sense index: 50\n",
            "Novelty score of the most novel sense: 118.0\n",
            "All novelty scores per sense: {0: 59.0, 1: -0.9833333333333333, 2: -0.9833333333333333, 3: 59.0, 4: -0.9833333333333333, 5: 59.0, 6: 59.0, 7: -0.9833333333333333, 8: -0.9833333333333333, 9: 59.0, 10: -0.9833333333333333, 11: 59.0, 12: 59.0, 13: -0.9833333333333333, 14: -0.9833333333333333, 15: -0.9833333333333333, 16: -0.9833333333333333, 17: -0.9833333333333333, 18: -0.9833333333333333, 19: 59.0, 20: -0.9833333333333333, 21: -0.9833333333333333, 22: 59.0, 23: -0.9833333333333333, 24: -0.9915966386554621, 25: -0.9833333333333333, 26: 59.0, 27: 59.0, 28: 59.0, 29: -0.9833333333333333, 30: -0.9833333333333333, 31: 59.0, 32: 59.0, 33: 59.0, 34: 59.0, 35: -0.9833333333333333, 36: 59.0, 37: -0.9833333333333333, 38: -0.9833333333333333, 39: -0.33146067415730335, 40: 59.0, 41: 59.0, 42: -0.9833333333333333, 43: 0.0, 44: 59.0, 45: 1.9666666666666666, 46: -0.9833333333333333, 47: 59.0, 48: 59.0, 49: 0.0, 50: 118.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: -0.9833333333333333, 55: 59.0, 56: 0.0, 57: 0.0, 58: 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count ref Counter({29: 2, 18: 2, 31: 1, 4: 1, 32: 1, 0: 1, 25: 1, 51: 1, 30: 1, 44: 1, 23: 1, 21: 1, 49: 1, 24: 1, 43: 1, 37: 1, 50: 1, 11: 1, 27: 1, 14: 1, 28: 1, 33: 1, 1: 1, 12: 1, 6: 1, 13: 1, 38: 1, 20: 1})\n",
        "count foc Counter({13: 2, 18: 2, 45: 2, 41: 1, 19: 1, 52: 1, 46: 1, 48: 1, 3: 1, 5: 1, 22: 1, 26: 1, 39: 1, 8: 1, 35: 1, 34: 1, 7: 1, 10: 1, 47: 1, 42: 1, 9: 1, 40: 1, 36: 1, 2: 1, 15: 1, 16: 1, 17: 1})\n",
        "Most novel sense index: 45\n",
        "Novelty score of the most novel sense: 120.0\n",
        "All novelty scores per sense: {0: -0.9836065573770493, 1: -0.9836065573770493, 2: 60.0, 3: 60.0, 4: -0.9836065573770493, 5: 60.0, 6: -0.9836065573770493, 7: 60.0, 8: 60.0, 9: 60.0, 10: 60.0, 11: -0.9836065573770493, 12: -0.9836065573770493, 13: 0.9836065573770493, 14: -0.9836065573770493, 15: 60.0, 16: 60.0, 17: 60.0, 18: 0.0, 19: 60.0, 20: -0.9836065573770493, 21: -0.9836065573770493, 22: 60.0, 23: -0.9836065573770493, 24: -0.9836065573770493, 25: -0.9836065573770493, 26: 60.0, 27: -0.9836065573770493, 28: -0.9836065573770493, 29: -0.9917355371900827, 30: -0.9836065573770493, 31: -0.9836065573770493, 32: -0.9836065573770493, 33: -0.9836065573770493, 34: 60.0, 35: 60.0, 36: 60.0, 37: -0.9836065573770493, 38: -0.9836065573770493, 39: 60.0, 40: 60.0, 41: 60.0, 42: 60.0, 43: -0.9836065573770493, 44: -0.9836065573770493, 45: 120.0, 46: 60.0, 47: 60.0, 48: 60.0, 49: -0.9836065573770493, 50: -0.9836065573770493, 51: -0.9836065573770493, 52: 60.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0}"
      ],
      "metadata": {
        "id": "F71mBWtfEhLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speaker 2"
      ],
      "metadata": {
        "id": "vYsFy8UXUZ_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'speaker2.xlsx'\n",
        "folder_path = '/content/drive/My Drive/MSc Computer Science/Master Thesis/trial_data/'\n",
        "\n",
        "df_s2 = pd.read_excel(folder_path + filename)\n",
        "#df_s2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QT5tdnCnUZuG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs2_usages = df_s2[df_s2['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s2_usages = df_s2[df_s2['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()"
      ],
      "metadata": {
        "id": "ncijh-hMUuT4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s2 = train_model(gs2_usages, s2_usages, seed=1905)"
      ],
      "metadata": {
        "id": "wtwr0yZk5mRW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSD"
      ],
      "metadata": {
        "id": "rakuj0MIBAJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_forms_s2 = get_word_forms_by_stem(gs2_usages, s2_usages, tw)\n",
        "word_forms_s2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK6D5WFDA_mX",
        "outputId": "265b2be5-4e3f-4f5a-aa57-18f91f4d0891"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bærekraft', 'bærekraftig', 'bærekraftige']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distr_gs2, distr_s2 = word_topic_distributions_corpus_pair(model_s2, gs2_usages, s2_usages)"
      ],
      "metadata": {
        "id": "_xdeuw_7B4wS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_jsd_for_lemma(distr_gs2, distr_s2, word_forms_s2) # 0.7864538886097446"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgAqrChoB8SG",
        "outputId": "1541e960-84b3-4707-eb45-c9198774f51f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7819907604003781"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Novelty"
      ],
      "metadata": {
        "id": "jIEcAWFnCXfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s2_topics = get_topic_word_lists(model_s1)"
      ],
      "metadata": {
        "id": "EEQxDkZHgvVa"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(s2_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIbSFdGcZLwB",
        "outputId": "fcce9cf6-9529-4f22-85e0-f974ddb0e825"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_novelty_sense, max_novelty_score, novelty_scores = compute_noveltyy(\n",
        "    gs2_usages, s2_usages, s2_topics)\n",
        "\n",
        "print(\"Most novel sense index:\", max_novelty_sense)\n",
        "print(\"Novelty score of the most novel sense:\", max_novelty_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz8xajInU3cf",
        "outputId": "3a9f66bd-38b9-465b-d40c-c56251a78426"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count ref Counter({39: 25, 27: 1, 14: 1, 2: 1, 45: 1, 35: 1})\n",
            "count foc Counter({39: 23, 45: 4, 46: 1, 25: 1, 13: 1})\n",
            "Most novel sense index: 13\n",
            "Novelty score of the most novel sense: 59.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count ref Counter({18: 22, 20: 2, 32: 2, 3: 1, 0: 1, 10: 1, 13: 1})\n",
        "count foc Counter({18: 23, 13: 4, 44: 1, 27: 1, 30: 1})\n",
        "Most novel sense index: 27\n",
        "Novelty score of the most novel sense: 60.0"
      ],
      "metadata": {
        "id": "YRYcNrJzEfau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speaker 3"
      ],
      "metadata": {
        "id": "WCCTldVNhoo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'speaker3.xlsx'\n",
        "folder_path = '/content/drive/My Drive/MSc Computer Science/Master Thesis/trial_data/'\n",
        "\n",
        "df_s3 = pd.read_excel(folder_path + filename)\n",
        "#df_s3"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IsWa_2U3VDe8"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs3_usages = df_s3[df_s3['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s3_usages = df_s3[df_s3['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()"
      ],
      "metadata": {
        "id": "Aq6jbTc0hyAg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s3 = train_model(gs3_usages, s3_usages)"
      ],
      "metadata": {
        "id": "ooo-4Nws66nt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSD"
      ],
      "metadata": {
        "id": "BsVhdzFdCqX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tw = 'bærekraft'\n",
        "word_forms_s3 = get_word_forms_by_stem(gs3_usages, s3_usages, tw)\n",
        "word_forms_s3\n",
        "\n",
        "# ['bærekraft', 'bærekraften', 'bærekraftig', 'bærekraftige', 'bærekraftmål', 'bærekraftmålene', 'bærekraftsmål', 'bærekraftsmålene']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQSURvzpCqBL",
        "outputId": "bca1cacc-4b69-4115-e98d-2c60c3f7cfd9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bærekraft',\n",
              " 'bærekraften',\n",
              " 'bærekraftig',\n",
              " 'bærekraftige',\n",
              " 'bærekraftmål',\n",
              " 'bærekraftmålene',\n",
              " 'bærekraftsmål',\n",
              " 'bærekraftsmålene']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distr_gs3, distr_s3 = word_topic_distributions_corpus_pair(model_s3, gs3_usages, s3_usages)"
      ],
      "metadata": {
        "id": "f0LSSbXNDXcb"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_jsd_for_lemma(distr_gs3, distr_s3, word_forms_s3) # 0.8268549337358913"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGGaoEn9Dari",
        "outputId": "b6cb593a-b971-4862-b149-0be474596d62"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8211156936308213"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Novelty"
      ],
      "metadata": {
        "id": "j0RMDQm7DpCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s3_topics = get_topic_word_lists(model_s3)"
      ],
      "metadata": {
        "id": "hhATVOS66_jE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(s3_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "138uYx-Ch7lr",
        "outputId": "0eeaaa0f-91cb-4a3e-b823-5d152a333d0f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_novelty_sense, max_novelty_score, novelty_scores = compute_noveltyy(\n",
        "    gs3_usages, s3_usages, s3_topics)\n",
        "\n",
        "print(\"Most novel sense index:\", max_novelty_sense)\n",
        "print(\"Novelty score of the most novel sense:\", max_novelty_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfto0cJ8iA7W",
        "outputId": "21d5803e-781c-4197-a605-1bf73ddbdfde"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count ref Counter({41: 2, 26: 2, 39: 1, 43: 1, 28: 1, 21: 1, 53: 1, 23: 1, 9: 1, 17: 1, 7: 1, 37: 1, 6: 1, 49: 1, 1: 1, 0: 1, 25: 1, 38: 1, 47: 1, 27: 1, 3: 1, 32: 1, 30: 1, 10: 1, 24: 1, 35: 1, 16: 1, 14: 1})\n",
            "count foc Counter({51: 2, 55: 2, 20: 1, 56: 1, 12: 1, 40: 1, 44: 1, 4: 1, 29: 1, 8: 1, 52: 1, 15: 1, 42: 1, 39: 1, 36: 1, 31: 1, 11: 1, 18: 1, 45: 1, 46: 1, 5: 1, 0: 1, 13: 1, 48: 1, 34: 1, 33: 1, 2: 1, 22: 1})\n",
            "Most novel sense index: 51\n",
            "Novelty score of the most novel sense: 124.00000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count ref Counter({42: 16, 28: 3, 8: 2, 6: 2, 32: 1, 7: 1, 35: 1, 2: 1, 11: 1, 40: 1, 23: 1})\n",
        "count foc Counter({42: 19, 13: 2, 9: 2, 28: 2, 4: 1, 14: 1, 6: 1, 45: 1, 2: 1})\n",
        "Most novel sense index: 9\n",
        "Novelty score of the most novel sense: 102.0\n",
        "Average novelty score: 6.852667635153881"
      ],
      "metadata": {
        "id": "HBQvLSRoEcyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speaker 4"
      ],
      "metadata": {
        "id": "PtVaDVTWiKAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'speaker4.xlsx'\n",
        "folder_path = '/content/drive/My Drive/MSc Computer Science/Master Thesis/trial_data/'\n",
        "\n",
        "df_s4 = pd.read_excel(folder_path + filename)\n",
        "#df_s4"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EasjrldUiLop"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs4_usages = df_s4[df_s4['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s4_usages = df_s4[df_s4['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()"
      ],
      "metadata": {
        "id": "7rFr731lio6B"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s4 = train_model(gs4_usages, s4_usages)"
      ],
      "metadata": {
        "id": "asBBjPi17SZo"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSD"
      ],
      "metadata": {
        "id": "5_e5CKRSExx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_forms_s4 = get_word_forms_by_stem(gs4_usages, s4_usages, tw)\n",
        "word_forms_s4\n",
        "# ['bærekraft','bærekraften','bærekraftig', 'bærekraftige', 'bærekraftighetsspørsmålene', 'bærekraftsinformasjon', 'bærekraftskrav', 'bærekraftsmål', 'bærekraftsmålene']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9e8XjHREzGx",
        "outputId": "8b094702-c9cb-46dc-986f-8ab985f58f27"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bærekraft',\n",
              " 'bærekraften',\n",
              " 'bærekraftig',\n",
              " 'bærekraftige',\n",
              " 'bærekraftighetsspørsmålene',\n",
              " 'bærekraftsinformasjon',\n",
              " 'bærekraftskrav',\n",
              " 'bærekraftsmål',\n",
              " 'bærekraftsmålene']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distr_gs4, distr_s4 = word_topic_distributions_corpus_pair(model_s4, gs4_usages, s4_usages)"
      ],
      "metadata": {
        "id": "xnxPjJFm7Od2"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_jsd_for_lemma(distr_gs4, distr_s4, word_forms_s4) # 0.8152904133872028"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_53GhmrAFGoY",
        "outputId": "59d45fb7-606a-4aa1-9104-11ef0169b92b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8036280476082095"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Novelty"
      ],
      "metadata": {
        "id": "uBHw7LyXFOIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s4_topics = get_topic_word_lists(model_s4)"
      ],
      "metadata": {
        "id": "omyAO_7u7d4C"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(s4_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC3YxNNriuWT",
        "outputId": "4fbd3855-8afa-4ca1-8860-77e7e5d52fde"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_novelty_sense, max_novelty_score, novelty_scores = compute_noveltyy(\n",
        "    gs4_usages, s4_usages, s4_topics)\n",
        "\n",
        "print(\"Most novel sense index:\", max_novelty_sense)\n",
        "print(\"Novelty score of the most novel sense:\", max_novelty_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb1lk9_4ix7h",
        "outputId": "1535acd7-faef-42e6-eee1-6a63774361b1"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count ref Counter({3: 2, 50: 1, 14: 1, 9: 1, 29: 1, 13: 1, 5: 1, 37: 1, 30: 1, 49: 1, 6: 1, 31: 1, 41: 1, 32: 1, 40: 1, 2: 1, 44: 1, 27: 1, 47: 1, 4: 1, 26: 1, 28: 1, 20: 1, 18: 1, 1: 1, 21: 1, 16: 1, 7: 1, 55: 1})\n",
            "count foc Counter({20: 2, 22: 2, 53: 2, 35: 1, 17: 1, 25: 1, 8: 1, 45: 1, 54: 1, 43: 1, 12: 1, 39: 1, 51: 1, 52: 1, 10: 1, 42: 1, 48: 1, 33: 1, 46: 1, 19: 1, 24: 1, 38: 1, 11: 1, 34: 1, 0: 1, 15: 1, 23: 1})\n",
            "Most novel sense index: 22\n",
            "Novelty score of the most novel sense: 124.00000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count ref Counter({47: 2, 43: 1, 20: 1, 5: 1, 12: 1, 6: 1, 1: 1, 19: 1, 55: 1, 23: 1, 49: 1, 36: 1, 28: 1, 59: 1, 14: 1, 22: 1, 39: 1, 53: 1, 8: 1, 21: 1, 11: 1, 48: 1, 17: 1, 16: 1, 45: 1, 0: 1, 15: 1, 9: 1, 32: 1})\n",
        "count foc Counter({17: 2, 41: 2, 10: 1, 51: 1, 38: 1, 35: 1, 31: 1, 56: 1, 42: 1, 34: 1, 52: 1, 46: 1, 3: 1, 18: 1, 37: 1, 44: 1, 24: 1, 54: 1, 33: 1, 30: 1, 45: 1, 7: 1, 25: 1, 2: 1, 13: 1, 27: 1, 40: 1, 50: 1})\n",
        "Most novel sense index: 41\n",
        "Novelty score of the most novel sense: 128.0"
      ],
      "metadata": {
        "id": "ETjctGx0GJql"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "paO9gFTEGjHH",
        "4rF3H3dAuHSL",
        "T4Q-HQnRuY9e",
        "qIFODwrFEiyE"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}