{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "tw = \"bærekraft\""
      ],
      "metadata": {
        "id": "r8AdDVa6h86U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount the Disk\n"
      ],
      "metadata": {
        "id": "vqv_Rf8TUtza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWLEDWw3UxWr",
        "outputId": "4023fad2-0202-4c53-dd89-45f06f67fb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz4QDtu9rhOG"
      },
      "source": [
        "# Helpers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "def affinity_prop(embeddings_r, embeddings_f):\n",
        "    all_embeddings = np.vstack([embeddings_r, embeddings_f])\n",
        "    sim_matrix = cosine_similarity(all_embeddings)\n",
        "\n",
        "    aff = AffinityPropagation(affinity='precomputed', random_state=42)\n",
        "    aff.fit(sim_matrix)\n",
        "\n",
        "    return aff.labels_\n",
        "\n",
        "def compute_binary_change(labels, embeddings1_len, label1='cr', label2='cf', k=0, n=1):\n",
        "    labels1 = [label1] * embeddings1_len\n",
        "    labels2 = [label2] * (len(labels) - embeddings1_len)\n",
        "    full_labels = labels1 + labels2\n",
        "\n",
        "    clusters = {}\n",
        "    for idx, cluster_id in enumerate(labels):\n",
        "        if cluster_id not in clusters:\n",
        "            clusters[cluster_id] = []\n",
        "        clusters[cluster_id].append(full_labels[idx])\n",
        "\n",
        "    cluster_list = list(clusters.values())\n",
        "    D, E = compute_sfd(cluster_list, label1, label2)\n",
        "    binary = classify_change_binary(D, E, k, n)\n",
        "    return binary, D, E, cluster_list\n",
        "\n",
        "def compute_sfd(clusters, c1_label, c2_label):\n",
        "    D = []\n",
        "    E = []\n",
        "\n",
        "    for cluster in clusters:\n",
        "        count_c1 = sum(1 for u in cluster if u == c1_label)\n",
        "        count_c2 = sum(1 for u in cluster if u == c2_label)\n",
        "        D.append(count_c1)\n",
        "        E.append(count_c2)\n",
        "\n",
        "    return D, E\n",
        "\n",
        "def classify_change_binary(D, E, k, n):\n",
        "    for d_i, e_i in zip(D, E):\n",
        "        if (d_i <= k and e_i >= n) or (d_i >= n and e_i <= k):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def compute_jsd(labels, embeddings1_len):\n",
        "    labels = np.array(labels)\n",
        "    labels1 = labels[:embeddings1_len]\n",
        "    labels2 = labels[embeddings1_len:]\n",
        "\n",
        "    all_cluster_ids = np.unique(labels)\n",
        "\n",
        "    counts1 = np.array([np.sum(labels1 == cid) for cid in all_cluster_ids])\n",
        "    counts2 = np.array([np.sum(labels2 == cid) for cid in all_cluster_ids])\n",
        "\n",
        "    print('counts1/ref', counts1)\n",
        "    print('counts2/foc', counts2)\n",
        "\n",
        "    prob1 = counts1 / counts1.sum()\n",
        "    prob2 = counts2 / counts2.sum()\n",
        "\n",
        "    jsd = jensenshannon(prob1, prob2)\n",
        "    return jsd, prob1, prob2\n"
      ],
      "metadata": {
        "id": "iMgF3l5ZsB_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "\n",
        "def compute_apd(embeddings_r, embeddings_f):\n",
        "    cdistances = cdist(embeddings_r, embeddings_f, metric='cosine')\n",
        "    return cdistances.mean()"
      ],
      "metadata": {
        "id": "mjmS_jt9AGYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_and_save_word_embeddings(\n",
        "    sentences,\n",
        "    target_forms,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    filename=\"word_embeddings.npy\",\n",
        "    batch_size=16,\n",
        "    device=\"cuda\"\n",
        "):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    tokenized_target_forms = [tokenizer.tokenize(form) for form in target_forms]\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(sentences), batch_size)):\n",
        "        batch = sentences[i:i + batch_size]\n",
        "        batch = [s.lower() for s in batch]\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_offsets_mapping=True,\n",
        "            add_special_tokens=True\n",
        "        )\n",
        "\n",
        "        offset_mapping = inputs.pop(\"offset_mapping\", None)\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            hidden_states = outputs.hidden_states\n",
        "\n",
        "        selected_layers = torch.stack(hidden_states[8:11]).sum(dim=0)\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "        for index, sentence in enumerate(batch):\n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids[index])\n",
        "            embeddings = selected_layers[index]\n",
        "\n",
        "            matching_indices = []\n",
        "            for target_token_seq in tokenized_target_forms:\n",
        "                for j in range(len(tokens) - len(target_token_seq) + 1):\n",
        "                    if tokens[j:j + len(target_token_seq)] == target_token_seq:\n",
        "                        matching_indices.extend(range(j, j + len(target_token_seq)))\n",
        "\n",
        "            matching_indices = sorted(set(matching_indices))\n",
        "            usage_embedding = embeddings[matching_indices].mean(dim=0)\n",
        "            all_embeddings.append(usage_embedding.cpu())\n",
        "\n",
        "            print(\"sentence\", sentence)\n",
        "            print(\"matched token indices\", matching_indices)\n",
        "            print(\"matched tokens\", [tokens[idx] for idx in matching_indices])\n",
        "\n",
        "\n",
        "        all_embeddings = torch.stack(all_embeddings)\n",
        "        np.save(filename, all_embeddings.numpy())\n"
      ],
      "metadata": {
        "id": "SOoNtGAqfXLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_word_forms_by_stem(usages_a, usages_b, stem):\n",
        "    all_usages = usages_a + usages_b\n",
        "    word_forms = set()\n",
        "\n",
        "    for text in all_usages:\n",
        "        tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "        for token in tokens:\n",
        "            if token.startswith(stem):\n",
        "                word_forms.add(token)\n",
        "\n",
        "    return sorted(word_forms)"
      ],
      "metadata": {
        "id": "V7ZicdK7guqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Only preliminary - Do not run again!\n"
      ],
      "metadata": {
        "id": "qaPcV6yWw_Np"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Load trial_data from excel"
      ],
      "metadata": {
        "id": "6bCKUtIocJTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_trial = '/content/drive/My Drive/MSc Computer Science/Master Thesis/trial_data/'\n",
        "\n",
        "for f in os.listdir(folder_path_trial):\n",
        "    print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W5AhsBWCYD8",
        "outputId": "fcd4e587-77ae-4a8d-f67e-84dd442873a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diachronic.xlsx\n",
            "speaker1.xlsx\n",
            "speaker2.xlsx\n",
            "speaker3.xlsx\n",
            "speaker4.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "trial_dia = pd.read_excel(folder_path_trial+'diachronic.xlsx')\n",
        "tg1_usages = trial_dia[trial_dia['usage_id'].str.contains(\"tg1\", na=False)]['text'].tolist()\n",
        "tg2_usages = trial_dia[trial_dia['usage_id'].str.contains(\"tg2\", na=False)]['text'].tolist()\n",
        "\n",
        "trial_s1 = pd.read_excel(folder_path_trial+'speaker1.xlsx')\n",
        "gs1_usages = trial_s1[trial_s1['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s1_usages = trial_s1[trial_s1['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()\n",
        "\n",
        "trial_s2 = pd.read_excel(folder_path_trial+'speaker2.xlsx')\n",
        "gs2_usages = trial_s2[trial_s2['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s2_usages = trial_s2[trial_s2['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()\n",
        "\n",
        "trial_s3 = pd.read_excel(folder_path_trial+'speaker3.xlsx')\n",
        "gs3_usages = trial_s3[trial_s3['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s3_usages = trial_s3[trial_s3['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()\n",
        "\n",
        "trial_s4 = pd.read_excel(folder_path_trial+'speaker4.xlsx')\n",
        "gs4_usages = trial_s4[trial_s4['usage_id'].str.contains(\"general\", na=False)]['text'].tolist()\n",
        "s4_usages = trial_s4[trial_s4['usage_id'].str.contains(\"speaker\", na=False)]['text'].tolist()"
      ],
      "metadata": {
        "id": "esMUvsRfCqRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tg1_usages))\n",
        "print(len(tg2_usages))\n",
        "print(len(gs1_usages))\n",
        "print(len(s1_usages))\n",
        "print(len(gs2_usages))\n",
        "print(len(s2_usages))\n",
        "print(len(gs3_usages))\n",
        "print(len(s3_usages))\n",
        "print(len(gs4_usages))\n",
        "print(len(s4_usages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG3TEcisEvzg",
        "outputId": "5f8feac5-7235-483a-e5f3-6311f0162b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "30\n",
            "30\n",
            "30\n",
            "30\n",
            "30\n",
            "30\n",
            "30\n",
            "30\n",
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word forms of corpus pairs"
      ],
      "metadata": {
        "id": "SgVOH3hYl94W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tw = \"bærekraft\"\n",
        "\n",
        "dia_word_forms = get_word_forms_by_stem(tg1_usages, tg2_usages, tw)\n",
        "print('dia word forms', dia_word_forms)\n",
        "\n",
        "s1_word_forms = get_word_forms_by_stem(gs1_usages, s1_usages, tw)\n",
        "print('s1 word forms', s1_word_forms)\n",
        "\n",
        "s2_word_forms = get_word_forms_by_stem(gs2_usages, s2_usages, tw)\n",
        "print('s2 word fomrs', s2_word_forms)\n",
        "\n",
        "s3_word_forms = get_word_forms_by_stem(gs3_usages, s3_usages, tw)\n",
        "print('s3 word forms', s3_word_forms)\n",
        "\n",
        "s4_word_forms = get_word_forms_by_stem(gs4_usages, s4_usages, tw)\n",
        "print('s4 word forms', s4_word_forms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUh9K9kLh6DN",
        "outputId": "ff939546-8125-4b59-c5dc-4c689f4a21ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dia word forms ['bærekraft', 'bærekraftig', 'bærekraftige', 'bærekraftmål', 'bærekraftsmålene', 'bærekraftutfordringene']\n",
            "s1 word forms ['bærekraft', 'bærekraftbegrepene', 'bærekraften', 'bærekraftig', 'bærekraftige', 'bærekraftindikator', 'bærekraftindikatorer', 'bærekraftperspektiv', 'bærekraftsindikatorer', 'bærekraftskriteriene', 'bærekraftskvalitet', 'bærekraftsmålet']\n",
            "s2 word fomrs ['bærekraft', 'bærekraftig', 'bærekraftige']\n",
            "s3 word forms ['bærekraft', 'bærekraften', 'bærekraftig', 'bærekraftige', 'bærekraftmål', 'bærekraftmålene', 'bærekraftsmål', 'bærekraftsmålene']\n",
            "s4 word forms ['bærekraft', 'bærekraften', 'bærekraftig', 'bærekraftige', 'bærekraftighetsspørsmålene', 'bærekraftsinformasjon', 'bærekraftskrav', 'bærekraftsmål', 'bærekraftsmålene']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate embeddings and save"
      ],
      "metadata": {
        "id": "h_7n3qUvrmvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PT: Embeddings trial_data"
      ],
      "metadata": {
        "id": "G5uOkFcLCT5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "model_name = \"NbAiLab/nb-bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, output_hidden_states=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq0ozLXNDZuD",
        "outputId": "a01e3bb2-e47c-410e-e5b6-d4b7801af93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_save_word_embeddings(tg1_usages, dia_word_forms, model, tokenizer, filename=\"base_tg1_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(tg2_usages, dia_word_forms, model, tokenizer, filename=\"base_tg2_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs1_usages, s1_word_forms, model, tokenizer, filename=\"base_gs1_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s1_usages, s1_word_forms, model, tokenizer, filename=\"base_s1_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs2_usages, s2_word_forms, model, tokenizer, filename=\"base_gs2_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s2_usages, s2_word_forms, model, tokenizer, filename=\"base_s2_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs3_usages, s3_word_forms, model, tokenizer, filename=\"base_gs3_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s3_usages, s3_word_forms, model, tokenizer, filename=\"base_s3_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs4_usages, s4_word_forms, model, tokenizer, filename=\"base_gs4_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s4_usages, s4_word_forms, model, tokenizer, filename=\"base_s4_wembeddings.npy\")"
      ],
      "metadata": {
        "id": "SLOZhFhFgYoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FT: Embeddings trial_data"
      ],
      "metadata": {
        "id": "kjnwWsi5NYpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/content/drive/MyDrive/nb-bert-finetuned\""
      ],
      "metadata": {
        "id": "7zqXberBNgVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "ft_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "ft_model = AutoModel.from_pretrained(model_dir, output_hidden_states=True)\n",
        "ft_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMeX9-gONlit",
        "outputId": "f9e0b17d-58b3-4448-b41f-34a3352755a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/nb-bert-finetuned and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_save_word_embeddings(tg1_usages, dia_word_forms, ft_model, ft_tokenizer, filename=\"ft_tg1_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(tg2_usages, dia_word_forms, ft_model, ft_tokenizer, filename=\"ft_tg2_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs1_usages, s1_word_forms, ft_model, ft_tokenizer, filename=\"ft_gs1_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s1_usages, s1_word_forms, ft_model, ft_tokenizer, filename=\"ft_s1_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs2_usages, s2_word_forms, ft_model, ft_tokenizer, filename=\"ft_gs2_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s2_usages, s2_word_forms, ft_model, ft_tokenizer, filename=\"ft_s2_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs3_usages, s3_word_forms, ft_model, ft_tokenizer, filename=\"ft_gs3_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s3_usages, s3_word_forms, ft_model, ft_tokenizer, filename=\"ft_s3_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(gs4_usages, s4_word_forms, ft_model, ft_tokenizer, filename=\"ft_gs4_wembeddings.npy\")\n",
        "generate_and_save_word_embeddings(s4_usages, s4_word_forms, ft_model, ft_tokenizer, filename=\"ft_s4_wembeddings.npy\")"
      ],
      "metadata": {
        "id": "yKS0FmSklQgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-trained Embeddings"
      ],
      "metadata": {
        "id": "uK2noL70tJuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load embeddings from Disk"
      ],
      "metadata": {
        "id": "soppFwBjX_2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "folder_path = '/content/drive/My Drive/MSc Computer Science/Master Thesis/pt-wembeddings'\n",
        "\n",
        "tg1_wembeddings = np.load(folder_path+'/base_tg1_wembeddings.npy')\n",
        "tg2_wembeddings = np.load(folder_path+'/base_tg2_wembeddings.npy')\n",
        "\n",
        "s1_wembeddings = np.load(folder_path+'/base_s1_wembeddings.npy')\n",
        "gs1_wembeddings = np.load(folder_path+'/base_gs1_wembeddings.npy')\n",
        "\n",
        "s2_wembeddings = np.load(folder_path+'/base_s2_wembeddings.npy')\n",
        "gs2_wembeddings = np.load(folder_path+'/base_gs2_wembeddings.npy')\n",
        "\n",
        "s3_wembeddings = np.load(folder_path+'/base_s3_wembeddings.npy')\n",
        "gs3_wembeddings = np.load(folder_path+'/base_gs3_wembeddings.npy')\n",
        "\n",
        "s4_wembeddings = np.load(folder_path+'/base_s4_wembeddings.npy')\n",
        "gs4_wembeddings = np.load(folder_path+'/base_gs4_wembeddings.npy')"
      ],
      "metadata": {
        "id": "J37_Vvasmhp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tg1_wembeddings.shape, tg2_wembeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTYWoARFaL3K",
        "outputId": "dd9db041-3c68-4d32-c51f-32e8a8529d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30, 768), (30, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1_wembeddings.shape, gs1_wembeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHgT9_m3GSXK",
        "outputId": "2c79dac1-3338-4495-9337-29db95bd6207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30, 768), (30, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s2_wembeddings.shape, gs2_wembeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnv9ZSngGUwK",
        "outputId": "5d6676ed-e95e-4ecb-8265-cc34ab552678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30, 768), (30, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s3_wembeddings.shape, gs3_wembeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gpgtXEBGWXI",
        "outputId": "9f4981ee-d8bc-48d9-ed14-c7c747336fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30, 768), (30, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s4_wembeddings.shape, gs4_wembeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UetQOLKKGYRd",
        "outputId": "1d42fca4-d7df-437b-da22-bd4e795235e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30, 768), (30, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSC"
      ],
      "metadata": {
        "id": "8E0cYafECGEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_labels = affinity_prop(tg1_wembeddings, tg2_wembeddings)\n",
        "\n",
        "binary, D, E, cluster_list = compute_binary_change(d_labels, len(tg1_wembeddings))\n",
        "jsd, _, _ = compute_jsd(d_labels, len(tg1_wembeddings))\n",
        "\n",
        "print('d binary', binary)\n",
        "print('d jsd', jsd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFVlFnl9sypY",
        "outputId": "e691eca6-0160-47cf-e90e-c2f963b98034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [1 8 4 7 1 1 0 0 0 6 2 0 0]\n",
            "counts2/foc [0 1 4 1 0 3 2 2 1 7 5 3 1]\n",
            "d binary 1\n",
            "d jsd 0.4912630278113394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1_labels = affinity_prop(gs1_wembeddings, s1_wembeddings)\n",
        "\n",
        "binary, D, E, cluster_list = compute_binary_change(s1_labels, len(gs1_wembeddings))\n",
        "jsd, _, _ = compute_jsd(s1_labels, len(gs1_wembeddings))\n",
        "\n",
        "print('s1 binary', binary)\n",
        "print('s1 jsd', jsd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JxewHNktOBr",
        "outputId": "f7cc743c-a7c8-4d0b-b6ff-7779bf10a907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [ 1  5  1 10  6  1  6  0]\n",
            "counts2/foc [ 0  1  3  0  8  3 10  5]\n",
            "s1 binary 1\n",
            "s1 jsd 0.4871867736832577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s2_labels = affinity_prop(gs2_wembeddings, s2_wembeddings)\n",
        "\n",
        "binary, D, E, cluster_list = compute_binary_change(s2_labels, len(gs2_wembeddings))\n",
        "jsd, _, _ = compute_jsd(s2_labels, len(gs2_wembeddings))\n",
        "\n",
        "print('s2 binary', binary)\n",
        "print('s2 jsd', jsd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35LJIOoBtTg1",
        "outputId": "774d9f5e-9d06-45f9-feac-34e1973cb38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [7 2 6 1 3 2 0 2 2 2 3]\n",
            "counts2/foc [2 1 0 2 2 2 1 7 4 2 7]\n",
            "s2 binary 1\n",
            "s2 jsd 0.395749719539728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s3_labels = affinity_prop(gs3_wembeddings, s3_wembeddings)\n",
        "\n",
        "binary, D, E, cluster_list = compute_binary_change(s3_labels, len(gs3_wembeddings))\n",
        "jsd, _, _ = compute_jsd(s3_labels, len(gs3_wembeddings))\n",
        "\n",
        "print('s3 binary', binary)\n",
        "print('s3 jsd', jsd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2BK-vcHtX2l",
        "outputId": "29053e09-a28a-4f6c-f558-0b8c00aeff73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [6 1 2 2 2 3 0 4 6 0 4]\n",
            "counts2/foc [0 0 0 1 1 4 1 6 6 9 2]\n",
            "s3 binary 1\n",
            "s3 jsd 0.4851532617696486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s4_labels = affinity_prop(gs4_wembeddings, s4_wembeddings)\n",
        "\n",
        "binary, D, E, cluster_list = compute_binary_change(s4_labels, len(gs4_wembeddings))\n",
        "jsd, _, _ = compute_jsd(s4_labels, len(gs4_wembeddings))\n",
        "\n",
        "print('s4 binary', binary)\n",
        "print('s4 jsd', jsd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNMMvN41tc1n",
        "outputId": "4b8bd313-baa4-41ff-97e9-d1231909d423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [3 9 2 5 1 2 3 3 0 0 2]\n",
            "counts2/foc [2 3 2 1 3 2 9 4 1 1 2]\n",
            "s4 binary 1\n",
            "s4 jsd 0.33358902600863366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('dia', compute_apd(tg1_wembeddings, tg2_wembeddings))\n",
        "print('s1', compute_apd(gs1_wembeddings, s1_wembeddings))\n",
        "print('s2', compute_apd(gs2_wembeddings, s2_wembeddings))\n",
        "print('s3', compute_apd(gs3_wembeddings, s3_wembeddings))\n",
        "print('s4', compute_apd(gs4_wembeddings, s4_wembeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSC7OG9ctqJ2",
        "outputId": "4a586b85-fdb6-4a6a-eabb-64fb4ff45a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dia 0.21523845138271708\n",
            "s1 0.25743089279124476\n",
            "s2 0.23038038709456088\n",
            "s3 0.24082329318894116\n",
            "s4 0.27179107343114395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuned Embeddings"
      ],
      "metadata": {
        "id": "v4f349qttnLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load embeddings from Disk"
      ],
      "metadata": {
        "id": "HJ34vibctwEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "folder_path_ft = '/content/drive/MyDrive/MSc Computer Science/Master Thesis/ft-wembeddings/'\n",
        "\n",
        "ft_tg1_wembeddings = np.load(folder_path_ft+\"ft_tg1_wembeddings.npy\")\n",
        "ft_tg2_wembeddings = np.load(folder_path_ft+\"ft_tg2_wembeddings.npy\")\n",
        "\n",
        "ft_gs1_wembeddings = np.load(folder_path_ft+\"ft_gs1_wembeddings.npy\")\n",
        "ft_s1_wembeddings = np.load(folder_path_ft+\"ft_s1_wembeddings.npy\")\n",
        "\n",
        "ft_gs2_wembeddings = np.load(folder_path_ft+\"ft_gs2_wembeddings.npy\")\n",
        "ft_s2_wembeddings = np.load(folder_path_ft+\"ft_s2_wembeddings.npy\")\n",
        "\n",
        "ft_gs3_wembeddings = np.load(folder_path_ft+\"ft_gs3_wembeddings.npy\")\n",
        "ft_s3_wembeddings = np.load(folder_path_ft+\"ft_s3_wembeddings.npy\")\n",
        "\n",
        "ft_gs4_wembeddings = np.load(folder_path_ft+\"ft_gs4_wembeddings.npy\")\n",
        "ft_s4_wembeddings = np.load(folder_path_ft+\"ft_s4_wembeddings.npy\")"
      ],
      "metadata": {
        "id": "t5NjJm_goIO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSC"
      ],
      "metadata": {
        "id": "xTMEcGfpCI_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_d_labels = affinity_prop(ft_tg1_wembeddings, ft_tg2_wembeddings)\n",
        "\n",
        "bc_d_ftw, D_d_ftw, E_d_ftw, cluster_list_d_ftw = compute_binary_change(ft_d_labels, len(ft_tg1_wembeddings))\n",
        "jsd_d_ftw, _, _ = compute_jsd(ft_d_labels, len(ft_tg1_wembeddings))\n",
        "\n",
        "print('d binary', binary)\n",
        "print('d clusters', cluster_list_d_ftw)\n",
        "print('d jsd', jsd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR_-SqYsuCVu",
        "outputId": "2221ce42-22ef-43bd-81cc-fa3ddcd3dd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [6 1 4 2 9 1 0 0 5 0 0 2]\n",
            "counts2/foc [1 0 5 1 2 3 2 1 6 4 3 2]\n",
            "d binary 1\n",
            "d clusters [['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf'], ['cr'], ['cr', 'cr', 'cf', 'cf'], ['cr', 'cr', 'cf'], ['cr', 'cf', 'cf', 'cf'], ['cf', 'cf', 'cf'], ['cf', 'cf'], ['cf', 'cf', 'cf', 'cf'], ['cf']]\n",
            "d jsd 0.33358902600863366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_s1_labels = affinity_prop(ft_gs1_wembeddings, ft_s1_wembeddings)\n",
        "\n",
        "bc_s1_ftw, D_s1_ftw, E_s1_ftw, cluster_list_s1_ftw = compute_binary_change(ft_s1_labels, len(ft_gs1_wembeddings))\n",
        "jsd_s1_ftw, _, _ = compute_jsd(ft_s1_labels, len(ft_gs1_wembeddings))\n",
        "\n",
        "print('s1 binary', bc_s1_ftw)\n",
        "print('s1 clusters', cluster_list_s1_ftw)\n",
        "print('s1 jsd', jsd_s1_ftw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqytHWF3u3dO",
        "outputId": "014e39e7-0200-4d49-8be4-f00ce23e9b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [ 6 10  6  2  1  5  0]\n",
            "counts2/foc [1 1 7 6 3 8 4]\n",
            "s1 binary 1\n",
            "s1 clusters [['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cf', 'cf', 'cf', 'cf']]\n",
            "s1 jsd 0.42788168652240177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_s2_labels = affinity_prop(ft_gs2_wembeddings, ft_s2_wembeddings)\n",
        "\n",
        "bc_s2_ftw, D_s2_ftw, E_s2_ftw, cluster_list_s2_ftw = compute_binary_change(ft_s2_labels, len(ft_gs2_wembeddings))\n",
        "jsd_s2_ftw, _, _ = compute_jsd(ft_s2_labels, len(ft_gs2_wembeddings))\n",
        "\n",
        "print('s2 binary', bc_s2_ftw)\n",
        "print('s2 clusters', cluster_list_s2_ftw)\n",
        "print('s2 jsd', jsd_s2_ftw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7akqrIIjvCiH",
        "outputId": "d461b357-8a30-467f-be33-0261b2848026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [6 2 1 5 3 4 4 0 2 3]\n",
            "counts2/foc [2 3 2 3 3 7 2 1 3 4]\n",
            "s2 binary 1\n",
            "s2 clusters [['cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cf', 'cf'], ['cf']]\n",
            "s2 jsd 0.23055585937245307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_s3_labels = affinity_prop(ft_gs3_wembeddings, ft_s3_wembeddings)\n",
        "\n",
        "bc_s3_ftw, D_s3_ftw, E_s3_ftw, cluster_list_s3_ftw = compute_binary_change(ft_s3_labels, len(ft_gs3_wembeddings))\n",
        "jsd_s3_ftw, _, _ = compute_jsd(ft_s3_labels, len(ft_gs3_wembeddings))\n",
        "\n",
        "print('s3 binary', bc_s3_ftw)\n",
        "print('s3 clusters', cluster_list_s3_ftw)\n",
        "print('s3 jsd', jsd_s3_ftw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdciRHqsvP-v",
        "outputId": "d06f3602-b0aa-4939-e2c3-7983054a18d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [6 4 1 2 4 6 2 0 5 0]\n",
            "counts2/foc [4 0 0 1 0 1 5 4 7 8]\n",
            "s3 binary 1\n",
            "s3 clusters [['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf'], ['cr'], ['cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cf'], ['cr', 'cr', 'cr', 'cr'], ['cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cf', 'cf', 'cf', 'cf']]\n",
            "s3 jsd 0.5437547106095686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_s4_labels = affinity_prop(ft_gs4_wembeddings, ft_s4_wembeddings)\n",
        "\n",
        "bc_s4_ftw, D_s4_ftw, E_s4_ftw, cluster_list_s4_ftw = compute_binary_change(ft_s4_labels, len(ft_gs4_wembeddings))\n",
        "jsd_s4_ftw, _, _ = compute_jsd(ft_s4_labels, len(ft_gs4_wembeddings))\n",
        "\n",
        "print('s4 binary', bc_s4_ftw)\n",
        "print('s4 clusters', cluster_list_s4_ftw)\n",
        "print('s4 jsd', jsd_s4_ftw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URbelyUQvZXG",
        "outputId": "7a2e324c-c737-46db-bd32-03f519bbe5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts1/ref [4 5 8 1 2 5 0 0 2 3 0]\n",
            "counts2/foc [3 3 3 3 2 9 1 1 3 1 1]\n",
            "s4 binary 1\n",
            "s4 clusters [['cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cr', 'cf'], ['cr', 'cr', 'cr', 'cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cr', 'cf', 'cf'], ['cr', 'cr', 'cf', 'cf', 'cf'], ['cr', 'cf', 'cf', 'cf'], ['cf'], ['cf'], ['cf']]\n",
            "s4 jsd 0.297477431172989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('dia', compute_apd(ft_tg1_wembeddings, ft_tg2_wembeddings))\n",
        "print('s1', compute_apd(ft_gs1_wembeddings, ft_s1_wembeddings))\n",
        "print('s2', compute_apd(ft_gs2_wembeddings, ft_s2_wembeddings))\n",
        "print('s3', compute_apd(ft_gs3_wembeddings, ft_s3_wembeddings))\n",
        "print('s4', compute_apd(ft_gs4_wembeddings, ft_s4_wembeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3S5N4afBpyZ",
        "outputId": "e4dfd871-6322-451c-a026-136049851367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dia 0.22757938878637252\n",
            "s1 0.27165569436746945\n",
            "s2 0.23531247244830306\n",
            "s3 0.2575774477257153\n",
            "s4 0.2940779636004815\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}